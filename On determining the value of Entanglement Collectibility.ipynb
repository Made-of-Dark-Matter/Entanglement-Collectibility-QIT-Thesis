{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50dfa19d",
   "metadata": {},
   "source": [
    "Quantum mechanics, since its inception, has remained a cornerstone of modern physics. Among\n",
    "its many intricate principles, quantum entanglement stands out as a quintessential phenomenon,\n",
    "underlying a myriad of both foundational discussions and practical applications. The capability to\n",
    "determine if a quantum state is entangled is not merely of theoretical interest, but is pivotal for\n",
    "advancing quantum technologies. As a result, the field of quantifying and detecting entanglement\n",
    "has been a very active. One known function called ’Entanglement Collectibility’ has been proposed\n",
    "[1, 2], as an essential metric to ascertain the entanglement of quantum states.\n",
    "\n",
    "The rigorous mathematical landscape of quantum mechanics has necessitated the adoption of sophis-\n",
    "ticated computational techniques. Within this milieu, the Gradient Descent algorithm, originating\n",
    "from the domain of optimization in machine learning, presents a promising approach. Gradient\n",
    "Descent’s ability to navigate complex functional spaces by iteratively adjusting parameters makes\n",
    "it apt for estimating intricate quantum functions.\n",
    "\n",
    "In this research endeavor, we systematically employ various variants of the Gradient Descent\n",
    "algorithm to estimate Entanglement Collectibility. Beyond mere estimation, this work critically\n",
    "evaluates the performance of these variants within the challenging context of quantum systems.\n",
    "Moreover, the thesis extends the application of these algorithms to derive significant quantities\n",
    "with experimental relevance, particularly sets of mutually orthogonal separable set of states and the\n",
    "associated observables. Through methodical computational examinations and robust analyses, this\n",
    "work aims to fortify the bridge between classical computational strategies and quantum mechanics,\n",
    "thereby contributing a refined set of tools to the quantum research paradigm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002dac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "# %matplotlib notebook\n",
    "\n",
    "import random\n",
    "import cmath,math\n",
    "from pprint import pprint\n",
    "import copy\n",
    "import time\n",
    "import itertools\n",
    "from itertools import count\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "from itertools import chain\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "#numpy,pandas and matplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Qutip imports\n",
    "from qutip import (Qobj, about, basis, coherent, coherent_dm, create, \n",
    "                  destroy,expect, fock, fock_dm, mesolve, qeye, sigmax, \n",
    "                  sigmay,sigmaz, tensor, thermal_dm,dimensions,\n",
    "                  rand_dm,rand_unitary,partial_transpose,\n",
    "                  hadamard_transform,projection,phase_basis)\n",
    "\n",
    "import qutip\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b910cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper functions for generating random unitaries, calculating collectibility and gradient. \n",
    "To generate random parameters with the prescribed range. \n",
    "'''\n",
    "def generate_Omega(delta):\n",
    "    Omega = random.uniform(0,delta)\n",
    "    return Omega\n",
    "\n",
    "def generate_alpha(delta):\n",
    "    alpha = random.uniform(0,2*math.pi*delta)\n",
    "    return alpha\n",
    "\n",
    "def generate_phi(r,s,delta,Omega):\n",
    "    phi = math.asin(Omega**(1/(2*r)))\n",
    "    return phi\n",
    "\n",
    "def generate_psi(r,s,delta):\n",
    "    psi = random.uniform(0,2*math.pi*delta)\n",
    "    return psi\n",
    "\n",
    "def generate_chi(r,s,delta):\n",
    "    chi = random.uniform(0,2*math.pi*delta)\n",
    "    return chi\n",
    "\n",
    "def para_i(r,s):\n",
    "    return (s**2-2*r-1, s**2-2*r, (s+1)**2-2*(s+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    These functions deal with matrix multiplications and tensor multiplication of a list of matrices. tge tensor_product_right and tensor_product_left function give a list of tensor products, each i-th element of which is the tensor product of first i elements of the inout matrix list. These are used to speed up the computation by storing the products before hand.\n",
    "'''\n",
    "def tensor_product(matrices):\n",
    "    if len(matrices) < 2:\n",
    "        raise ValueError(\"At least two matrices are required.\")\n",
    "\n",
    "    return reduce(np.kron, matrices)\n",
    "\n",
    "def tensor_product_left(tensors):\n",
    "    if len(tensors) < 2:\n",
    "        raise ValueError(\"At least two tensors are required.\")\n",
    "\n",
    "    result = [tensors[0]]\n",
    "    for i in range(1, len(tensors)):\n",
    "        result.append(np.kron(result[i-1], tensors[i]))\n",
    "\n",
    "    return result\n",
    "\n",
    "def tensor_product_right(tensors):\n",
    "    if len(tensors) < 2:\n",
    "        raise ValueError(\"At least two tensors are required.\")\n",
    "\n",
    "    result = [tensors[-1]]\n",
    "    for i in range(len(tensors)-2, -1, -1):\n",
    "        result.insert(0, np.kron(tensors[i], result[0]))\n",
    "\n",
    "    return result\n",
    "\n",
    "def multiply_right_matrices(matrices):\n",
    "    if len(matrices) < 2:\n",
    "        raise ValueError(\"At least two matrices are required.\")\n",
    "\n",
    "    result = [matrices[-1]]\n",
    "    for i in range(len(matrices)-2, -1, -1):\n",
    "        result.insert(0, np.matmul(matrices[i], result[0]))\n",
    "\n",
    "    return result\n",
    "\n",
    "def Series_matrix_multiply(matrix_lst):\n",
    "    return reduce(lambda a,b:np.matmul(a,b),matrix_lst)\n",
    "\\end{lstlisting}\n",
    "\n",
    "\\subsubsection{\\underline{Activation function}}\n",
    "\\label{code:Activation function}\n",
    "\\begin{lstlisting}[language = Python]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2328bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These functions deploy the activation function, to convert the original parameters to their sigmoid form and inverse as well.\n",
    "'''\n",
    "def min_max_para(symbol,delta):\n",
    "    if symbol=='alpha':\n",
    "        para_min = 0\n",
    "        para_max = 2*math.pi*delta\n",
    "    elif symbol == 'Omega':\n",
    "        para_min = 0\n",
    "        para_max = delta\n",
    "    elif symbol == 'psi':\n",
    "        para_min = 0\n",
    "        para_max = 2*math.pi*delta\n",
    "    elif symbol == 'chi':\n",
    "        para_min = 0\n",
    "        para_max = 2*math.pi*delta\n",
    "    \n",
    "    return para_min,para_max\n",
    "\n",
    "def sigmoid_function(symbol,num,delta):\n",
    "    try:\n",
    "        para_min,para_max = min_max_para(symbol,delta)\n",
    "        sigm_num = (1/(1+math.exp(-num)))*para_max\n",
    "        return sigm_num\n",
    "    except Exception as err:\n",
    "        print(f'{type(err)}: Error: {err} \\n sigmoid function error for symbol:{symbol}, num:{num}')\n",
    "\n",
    "def invert_sigmoid_function(symbol,num,delta):\n",
    "    para_min,para_max = min_max_para(symbol,delta)\n",
    "    invert_sigm_num = math.log(num/(para_max-num))\n",
    "    return invert_sigm_num  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUE parameter generator function -\n",
    "def CUE_parameter_generator(size,delta):\n",
    "    '''\n",
    "    input: \n",
    "    size = N (size of one side of the random unitary matrix \n",
    "    being produced), depending on which, this function return a parameter \n",
    "    array of size. \n",
    "    \n",
    "    delta = another user defined variable for determining random unitary\n",
    "    \n",
    "    return:\n",
    "    Returns an array of size (n-1)^2 with the structure -\n",
    "    [alpha,\n",
    "    \n",
    "    phi(1,2),\n",
    "    psi(1,2),\n",
    "    chi(1,2),\n",
    "    \n",
    "    phi(2,3),\n",
    "    psi(2,3),\n",
    "    phi(1,3),\n",
    "    psi(1,3),\n",
    "    chi(1,3),\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    phi(1,n),\n",
    "    psi(1,n),\n",
    "    chi(1,n),\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    parameters = []\n",
    "    alpha = generate_alpha(delta)\n",
    "    sigm_alpha = invert_sigmoid_function('alpha',alpha,delta)\n",
    "    parameters.append(['alpha',0,1,alpha,sigm_alpha])\n",
    "    \n",
    "    for s in range(2,size+1):\n",
    "        for r in range(s-1,0,-1):\n",
    "            Omega = generate_Omega(delta)\n",
    "            sigm_Omega = invert_sigmoid_function('Omega',Omega,delta)\n",
    "            parameters.append(['Omega',r,s,Omega,sigm_Omega])\n",
    "            \n",
    "            psi = generate_psi(r,s,delta)\n",
    "            sigm_psi = invert_sigmoid_function('psi',psi,delta)\n",
    "            parameters.append(['psi',r,s,psi,sigm_psi])\n",
    "            \n",
    "            if r==1:\n",
    "                chi = generate_chi(r,s,delta)\n",
    "                sigm_chi = invert_sigmoid_function('chi',chi,delta)\n",
    "                parameters.append(['chi',r,s,chi,sigm_chi])\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mutually_Orthogonal_state_generator(system):\n",
    "    '''\n",
    "    Used to generate mutually orthogonal basis for a given system.\n",
    "    Initially, the assumption is that all Hilbert spaces of the subsystem are of \n",
    "    the same dimension.\n",
    "    '''\n",
    "    N = min(system)\n",
    "    MO_Basis_set = []\n",
    "    for subsys_dim in system:\n",
    "        MO_Basis_subset = [basis(subsys_dim, n) for n in range(subsys_dim)]\n",
    "        MO_Basis_set.append(MO_Basis_subset)\n",
    "    return MO_Basis_set\n",
    "\n",
    "def Seperable_state_set_generator(MO_Basis_set):\n",
    "    '''\n",
    "    Used to produce N - Seperable state set.  \n",
    "    Initially, the assumption is that all Hilbert spaces of the subsystem are of \n",
    "    the same dimension.\n",
    "    '''\n",
    "    Seperable_basis_set = []\n",
    "    N = max([len(subsys) for subsys in MO_Basis_set])\n",
    "    for n in range(N): \n",
    "        Seperable_basis_set.append(tensor([subsys[n] for subsys in MO_Basis_set]))\n",
    "    return Seperable_basis_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Elementary_Unitary_Matrices_Generator(size,r,s,delta,Omega, psi, chi):\n",
    "    # Creating the Elementary 2D subsystem unitary matrix\n",
    "    E = np.eye(size, dtype=complex)\n",
    "    r-=1 \n",
    "    s-=1\n",
    "    \n",
    "    phi = math.asin(Omega**(1/(2*(r+1))))\n",
    "    \n",
    "    E[r,r] = math.cos(phi) * cmath.exp(complex(0,psi))  \n",
    "    E[r,s] = math.sin(phi) * cmath.exp(complex(0,chi))\n",
    "    E[s,r] = -math.sin(phi) * cmath.exp(complex(0,-chi))\n",
    "    E[s,s] = math.cos(phi) * cmath.exp(complex(0,-psi))\n",
    "    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40739503",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CUE_generator - \n",
    "First step is to work with unitary matrices. \n",
    "It will have a function to calculate random unitary matrix using Zyczkowski's method.\n",
    "'''\n",
    "def CUE_generator(size, parameters, delta):\n",
    "    '''\n",
    "    input: \n",
    "    \n",
    "    1) size = it is the dimensionality (of one side) of the aimed \n",
    "    random unitary matrix.\n",
    "    \n",
    "    2) parameters = This is a list of parameters used to parametrize the \n",
    "    unitary matrix, necessary to generate CUE(Circular Unitary Ensembles)\n",
    "    deterministically. It is crucial to keep track of these parameters to\n",
    "    eventually work with gradient descent.\n",
    "    \n",
    "    return:\n",
    "    1) return a unitary matrix of given size, with given parameters and \n",
    "    delta.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    alpha = float(parameters[0][3])\n",
    "    \n",
    "    Left = []\n",
    "    Elementary_matrices = [cmath.exp(complex(0,alpha))]\n",
    "    right = []\n",
    "    \n",
    "    for s in range(2,size+1):\n",
    "        for r in range(s-1,0,-1):\n",
    "            indexes = para_i(r,s)\n",
    "            Omega = float(parameters[indexes[0]][3])\n",
    "            psi = float(parameters[indexes[1]][3])\n",
    "            if r==1:\n",
    "                chi = float(parameters[indexes[2]][3])\n",
    "            else:\n",
    "                chi = 0\n",
    "            E = Elementary_Unitary_Matrices_Generator(size,r,s,delta,Omega,psi,chi)\n",
    "\n",
    "            if not Qobj(E).check_isunitary():\n",
    "                raise Exception('U is not unitary.')\n",
    "\n",
    "            Elementary_matrices.append(E)\n",
    "    \n",
    "    \n",
    "    Left_multiply = Series_multiply(Elementary_matrices,'left')\n",
    "    Right_multiply = Series_multiply(Elementary_matrices,'right')\n",
    "    U = Series_multiply(Elementary_matrices)\n",
    "    \n",
    "    if Qobj(U).check_isunitary():\n",
    "        return (U,Elementary_matrices, Left_multiply, Right_multiply)\n",
    "    else:\n",
    "        raise Exception('U is not unitary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd438c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Y values for given parameters.\n",
    "def Y_Calculator(sep_state_set,U,rho):\n",
    "    '''\n",
    "    Inputs: \n",
    "    sep_state_set = list of seperable state vectors\n",
    "    U_lst = the unitary to be applied for optimization\n",
    "    rho = the state of the system being tested for entanglement, given as a density matrix\n",
    "    \n",
    "    Outputs:\n",
    "    (Y,Y_list,left_Y, right_Y,Yij_matrix)\n",
    "    \n",
    "    where:\n",
    "    Y = The final calcuated value of Y, given value inputs.\n",
    "    \n",
    "    Y_list = The list of 'Y multiplier' \n",
    "    \n",
    "    left_Y = The list of multiplied <Y(i,j)> from the left: \n",
    "    [(<Y(1,1)>), (<Y(1,1)><Y(1,2)>),....,(<Y(1,1)>...<Y(N,N)>)]\n",
    "    \n",
    "    right_Y = The list of multiplied <Y(i,j)> from the right:\n",
    "    [(<Y(N,N)>), (<Y(N,N)><Y(N-1,N)>),....,(<Y(N,N)>...<Y(1,1)>)]\n",
    "    \n",
    "    '''\n",
    "    U = Qobj(U)\n",
    "    U_dag = U.dag()\n",
    "    \n",
    "    rho = Qobj(rho)\n",
    "\n",
    "    system_dim = len(sep_state_set)\n",
    "   \n",
    "\n",
    "    Y_list = []\n",
    "    Yij_list = []\n",
    "    Yij_matrix = []\n",
    "    \n",
    "    for i in range(system_dim):\n",
    "        Yij_matrix.append([])\n",
    "        for j in range(system_dim):\n",
    "            Y_multiplier = reduce(np.matmul,[np.array(sep_state_set[i].dag().full()),np.array(U_dag.full()),np.array(rho.full()),np.array(U.full()),np.array(sep_state_set[j].full())])\n",
    "            Yij_list.append([Y_multiplier[0][0],i,j])\n",
    "            Yij_matrix[i].append(Y_multiplier[0][0])\n",
    "            Y_list.append(Y_multiplier[0][0])\n",
    "    \n",
    "    Y = reduce(lambda a,b:a*b, Y_list)\n",
    "    Y = Y**(1/system_dim)\n",
    "\n",
    "    left_Y = Series_multiply(Y_list,'left')\n",
    "    right_Y = Series_multiply(Y_list,'right')\n",
    "    \n",
    "    return (Y,Yij_list,left_Y,right_Y,Yij_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dEdp(E,para,para_i,delta):\n",
    "'''\n",
    "For calculation of the dE/dp, derivative of Elementary 2D unitary matrix with respect to the parameter being considered.\n",
    "'''\n",
    "    symbol = para[para_i][0]\n",
    "    r = int(para[para_i][1])\n",
    "    s = int(para[para_i][2])\n",
    "    parameter_value = float(para[para_i][3])\n",
    "    sigm_parameter_value = float(para[para_i][4])\n",
    "    \n",
    "    para_min,para_max = min_max_para(symbol,delta)\n",
    "    \n",
    "    try:\n",
    "        exp_para = math.exp(-sigm_parameter_value)\n",
    "        dsigmapara_dpara = (exp_para*para_max)/((1+exp_para)**2)\n",
    "    except Exception as err:\n",
    "        print(f'{type(err)}: Error: {err}\\n exp_para:{exp_para},\\n para_max:{para_max},\\n sigm_parameter_value:{sigm_parameter_value}')\n",
    "        \n",
    "    chi=0\n",
    "    dEdp = np.zeros(E.shape, dtype=complex)\n",
    "    r_pow = r\n",
    "    r-=1 \n",
    "    s-=1\n",
    "        \n",
    "    try: \n",
    "        if symbol == 'Omega':\n",
    "            Omega = parameter_value\n",
    "            psi = float(para[para_i+1][3])\n",
    "            if r==1:\n",
    "                chi = float(para[para_i+2][3])\n",
    "\n",
    "            power = 1/(2*(r_pow))\n",
    "            z = Omega**(power)  \n",
    "\n",
    "            dEdp[r,r] = cmath.exp(complex(0,psi)) * -math.sin(math.asin(z)) * 1/(math.sqrt(1-z**2)) * power * (Omega**(power-1)) * dsigmapara_dpara\n",
    "            dEdp[r,s] = cmath.exp(complex(0,chi)) * math.cos(math.asin(z)) * 1/(math.sqrt(1-z**2)) * power * (Omega**(power-1)) * dsigmapara_dpara\n",
    "            dEdp[s,r] = -cmath.exp(complex(0,-chi)) * math.cos(math.asin(z)) * 1/(math.sqrt(1-z**2)) * power * (Omega**(power-1)) * dsigmapara_dpara\n",
    "            dEdp[s,s] = cmath.exp(complex(0,-psi)) * -math.sin(math.asin(z)) * 1/(math.sqrt(1-z**2)) * power * (Omega**(power-1)) * dsigmapara_dpara\n",
    "\n",
    "        elif symbol == 'psi':\n",
    "            Omega = float(para[para_i-1][3])\n",
    "            psi = parameter_value\n",
    "            if r==1:\n",
    "                chi = float(para[para_i+1][3])\n",
    "\n",
    "            power = 1/(2*(r_pow))\n",
    "            z = Omega**(power)\n",
    "            phi = math.asin(z)        \n",
    "\n",
    "            dEdp[r,r] = complex(0,1) * math.cos(phi) * cmath.exp(complex(0,psi)) *  dsigmapara_dpara\n",
    "            dEdp[r,s] = 0\n",
    "            dEdp[s,r] = 0\n",
    "            dEdp[s,s] = -complex(0,1) * math.cos(phi) * cmath.exp(complex(0,-psi)) *  dsigmapara_dpara\n",
    "\n",
    "        elif symbol == 'chi':\n",
    "            Omega = float(para[para_i-2][3])\n",
    "            psi = float(para[para_i-1][3])\n",
    "            if r==1:\n",
    "                chi = parameter_value\n",
    "\n",
    "            power = 1/(2*(r_pow))\n",
    "            z = Omega**(power)\n",
    "            phi = math.asin(z)\n",
    "\n",
    "            dEdp[r,r] = 0  \n",
    "            dEdp[r,s] = complex(0,1) * math.sin(phi) * cmath.exp(complex(0,chi)) *  dsigmapara_dpara\n",
    "            dEdp[s,r] = -complex(0,1) * -math.sin(phi) * cmath.exp(complex(0,-chi)) *  dsigmapara_dpara\n",
    "            dEdp[s,s] = 0\n",
    "    except Exception as err:\n",
    "        print(f'{type(err)}: Error:{err}\\n z: {z}')\n",
    "        \n",
    "    return dEdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63674945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_du_system_dp(u_system, para,para_i,sys_i,delta):\n",
    "'''\n",
    "For calculation of the du/dp, derivative of local unitary matrix with respect to the parameter p.\n",
    "'''\n",
    "\n",
    "    symbol = para[para_i][0]\n",
    "    r = float(para[para_i][1])\n",
    "    s = float(para[para_i][2])\n",
    "    parameter_value = float(para[para_i][3])\n",
    "    sigm_parameter_value = float(para[para_i][4])\n",
    "    \n",
    "    \n",
    "    if symbol=='alpha':\n",
    "        return complex(0,1)*sigm_parameter_value*u_system[0]\n",
    "    \n",
    "    elementary_index = int((s-1)*(s)/2 - (r-1))\n",
    "    E = u_system[1][elementary_index]\n",
    "\n",
    "    dEdp = calculate_dEdp(E,para,para_i,delta)\n",
    "    \n",
    "    if elementary_index == 0:\n",
    "        du_system_dp = Series_multiply([dEdp,u_system[3][sys_i+1]])\n",
    "    elif elementary_index == len(u_system[1])-1:\n",
    "        du_system_dp = Series_multiply([u_system[2][elementary_index-1],dEdp])\n",
    "    else:\n",
    "        du_system_dp = Series_multiply([u_system[2][sys_i-1],dEdp,u_system[3][sys_i+1]])\n",
    "        \n",
    "    return du_system_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a450260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dUdp(U,para,sys_i,para_i,Total_U,right_tensor_product,left_tensor_product,delta):\n",
    "    '''\n",
    "    For calculation of the dU/dp, derivative of global unitary (tensor product of all local unitaries) matrix with respect to the parameter p.\n",
    "    '''\n",
    "    u_system = U[sys_i]\n",
    "    du_system_dp = calculate_du_system_dp(u_system, para,para_i,sys_i,delta)\n",
    "    \n",
    "    if sys_i == 0:\n",
    "        dUdp = tensor_product([du_system_dp,right_tensor_product[sys_i+1]])\n",
    "    elif sys_i == len(U)-1:\n",
    "        dUdp = tensor_product([left_tensor_product[sys_i-1],du_system_dp])\n",
    "    else:\n",
    "        dUdp = tensor_product([left_tensor_product[sys_i-1],du_system_dp,right_tensor_product[sys_i+1]])\n",
    "    \n",
    "    return dUdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0804c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Yij_dp_diagonal(sep_state_set,rho,U,para,sys_i,para_i,xi_a,xi_b,Total_U,right_tensor_product,left_tensor_product,delta):\n",
    "    '''\n",
    "    For calculation of the dYii/dp, derivative of the diagonal multipliers Yii (i=1,2,...,N), which constitute collectibility function Y, with respect to the parameter p.\n",
    "    '''\n",
    "    Total_U_dag = np.array(Total_U).transpose().conjugate()\n",
    "    xi_a_dag = np.array(xi_a).transpose().conjugate()\n",
    "      \n",
    "    dUdp = calculate_dUdp(U,para,sys_i,para_i,Total_U,right_tensor_product,left_tensor_product,delta)\n",
    "    dUdp_dag = np.array(dUdp).transpose().conjugate()\n",
    "    \n",
    "    dYij_dp = Series_matrix_multiply([xi_a_dag,dUdp_dag,np.array(rho),Total_U,np.array(xi_b)])\n",
    "    \n",
    "    return dYij_dp[0][0]\n",
    "\n",
    "def calculate_Yij_dp_off_diagonal(sep_state_set,rho,U,para,sys_i,para_i,xi_a,xi_b,Total_U,right_tensor_product,left_tensor_product,delta):\n",
    "    '''\n",
    "    For calculation of the dYij/dp, derivative of the non-diagonal multipliers Yij (i,j=1,2,...,N), which constitute collectibility function Y, with respect to the parameter p.\n",
    "    '''\n",
    "\n",
    "    Total_U_dag = np.array(Total_U).transpose().conjugate()\n",
    "    xi_a_dag = np.array(xi_a).transpose().conjugate()\n",
    "      \n",
    "    dUdp = calculate_dUdp(U,para,sys_i,para_i,Total_U,right_tensor_product,left_tensor_product,delta)\n",
    "    dUdp_dag = np.array(dUdp).transpose().conjugate()\n",
    "    \n",
    "    term_a = Series_matrix_multiply([xi_a_dag,dUdp_dag,np.array(rho),Total_U,np.array(xi_b)])\n",
    "    term_b = Series_matrix_multiply([xi_a_dag,Total_U_dag,np.array(rho),dUdp,np.array(xi_b)])\n",
    "    \n",
    "    dYij_dp = term_a + term_b\n",
    "    \n",
    "    return dYij_dp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dY_dp_modified(sep_state_set,rho,U,para,Y,sys_i,para_i,Total_U,right_tensor_product,left_tensor_product,delta):\n",
    "    '''\n",
    "    For calculation of the dY/dp, derivative of the Collectibility function Y, with respect to the parameter p.\n",
    "    '''\n",
    "    y = Y[4]\n",
    "    \n",
    "    partial_diff_sum = 0\n",
    "    abs = lambda f:math.sqrt(f.real**2+f.imag**2)\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        for j in range(len(y[i])):\n",
    "            xi_a = sep_state_set[i]\n",
    "            xi_b = sep_state_set[j]\n",
    "\n",
    "            if i==j:\n",
    "                y_original = y[i][j]\n",
    "                dYij_dp = calculate_Yij_dp_diagonal(sep_state_set,rho,U,para,sys_i,para_i,xi_a,xi_b,Total_U,right_tensor_product,left_tensor_product,delta)\n",
    "                dYij_dp = 2*dYij_dp.real\n",
    "                partial_diff_sum+=((dYij_dp)/abs(y_original))\n",
    "            elif i<j:\n",
    "                Yij = y[i][j]\n",
    "                Yji = y[j][i]\n",
    "                y_original = Yij*Yji\n",
    "    \n",
    "                dYij_dp = calculate_Yij_dp_off_diagonal(sep_state_set,rho,U,para,sys_i,para_i,xi_a,xi_b,Total_U,right_tensor_product,left_tensor_product,delta)\n",
    "                dYij_dp = dYij_dp*Yji\n",
    "                dYij_dp = 2*dYij_dp.real\n",
    "\n",
    "                partial_diff_sum+=((dYij_dp)/((abs(y_original))**2))\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    dYdp = abs(Y[0])*partial_diff_sum\n",
    "    return dYdp.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient(sep_state_set,rho,U,parameters,delta):\n",
    "    '''\n",
    "    This function calculates Gradient of Collectibility function Y for each parameter in the parameter vector, returning a gradient vector.\n",
    "    U is a list of local unitaries = [U_1,U_2,....,U_k]\n",
    "    '''\n",
    "    Local_unitary_list = [U[n][0] for n in range(len(U))]\n",
    "    Total_U = tensor_product(Local_unitary_list)\n",
    "    right_tensor_product = tensor_product_right(Local_unitary_list)\n",
    "    left_tensor_product = tensor_product_left(Local_unitary_list)\n",
    "    \n",
    "    Y = Y_Calculator(sep_state_set, Total_U, rho)\n",
    "    gradient = []\n",
    "    for sys_i in range(len(parameters)):\n",
    "        gradient.append([])\n",
    "        for para_i in range(len(parameters[sys_i])):\n",
    "            para = parameters[sys_i]\n",
    "            dYdp = calculate_dY_dp_modified(sep_state_set,rho,U,para,Y,sys_i,para_i,Total_U,right_tensor_product,left_tensor_product,delta)\n",
    "            gradient[sys_i].append(dYdp)\n",
    "            \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These are helper function for Gradient Descent fucntion:\n",
    "'''\n",
    "def shifting_sigm_parameters(parameters, shift_in_para, delta):\n",
    "    for sys in range(len(parameters)):\n",
    "        for para in range(len(parameters[sys])):\n",
    "            a = parameters[sys][para][4]\n",
    "            b = shift_in_para[sys][para]\n",
    "            \n",
    "            c = sigmoid_function(parameters[sys][para][0],a+b,delta)\n",
    "            \n",
    "            parameters[sys][para][3] = c\n",
    "            parameters[sys][para][4] = a+b\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def parameter_based_unitary(parameters,delta):\n",
    "    U = []\n",
    "    for p in parameters:\n",
    "        size = int(math.sqrt(len(p)))\n",
    "        \n",
    "        uni = CUE_generator(size, p, delta)\n",
    "        U.append(uni)\n",
    "        \n",
    "    return U\n",
    "\n",
    "\n",
    "def Y_calculator_wrapper(sep_state_set, rho, U):\n",
    "    \n",
    "    Local_unitary_list = [U[n][0] for n in range(len(U))]\n",
    "    \n",
    "    Total_U = tensor_product(Local_unitary_list)\n",
    "    \n",
    "    Y = Y_Calculator(sep_state_set, Total_U,rho)\n",
    "    return Y\n",
    "    \n",
    "'''\n",
    "Important function! lising the hyperparameters for various gradient descent adaptations.\n",
    "'''\n",
    "def dynamic_stepsize():\n",
    "    stepsize = 0.1\n",
    "    \n",
    "    momentum_decay_rate = 0.9\n",
    "    RMSProp_decay_rate = 0.58\n",
    "    \n",
    "    Adam_Beta_momentum = 0.8\n",
    "    Adam_Beta_RMS = 0.9\n",
    "    \n",
    "    return (stepsize,momentum_decay_rate,RMSProp_decay_rate,Adam_Beta_momentum,Adam_Beta_RMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b46d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function runs the Gradient Descent of a given form (method) for given iterations and returns the list of collectibility estimates and corresponding paramters. Output of this function, after multiple runs, is used to give the final approximation of collectibility.\n",
    "'''\n",
    "def Gradient_Descent(system,rho,delta,max_iterations,return_parameters,method = 'RMSProp'):\n",
    "    abs = lambda f:math.sqrt(f.real**2+f.imag**2)\n",
    "    sep_state_set = Seperable_state_set_generator(Mutually_Orthogonal_state_generator(system))\n",
    "    \n",
    "    parameters = []\n",
    "    for n in system:\n",
    "        size = n\n",
    "        p = CUE_parameter_generator(size, delta)\n",
    "        parameters.append(p)\n",
    "    \n",
    "    U = parameter_based_unitary(parameters,delta)\n",
    "    \n",
    "    Y = Y_calculator_wrapper(sep_state_set, rho, U)\n",
    "    \n",
    "    Y_old = abs(Y[0]).real\n",
    "    Y_correction = [Y_old]\n",
    "    \n",
    "    Y_correction_max = max(Y_correction)\n",
    "    \n",
    "    if method in ['Random']:\n",
    "        Y_correction = [Y_old,Y_old]\n",
    "        if return_parameters:\n",
    "            return Y_correction,(Y_correction_max,parameters)\n",
    "        else:\n",
    "            return Y_correction\n",
    "    \n",
    "    gradient_sum = np.zeros((len(parameters),len(parameters[0])))\n",
    "    gradient_sum_square = np.zeros((len(parameters),len(parameters[0])))\n",
    "    \n",
    "    (stepsize,momentum_decay_rate,RMSProp_decay_rate,Adam_Beta_momentum,Adam_Beta_RMS) = dynamic_stepsize()\n",
    "    nrm = math.inf\n",
    "    stepsize_list = [0]\n",
    "    \n",
    "    if method in ['Gradient_Descent','AdaGrad','RMSProp']:\n",
    "        while Y_correction_max == Y_correction[-1] and len(Y_correction)<=max_iterations:\n",
    "            \n",
    "            gradient = Gradient(sep_state_set,rho,U,parameters,delta) \n",
    "            gradient = np.array(gradient)\n",
    "            nrm = np.linalg.norm(gradient)\n",
    "\n",
    "            if method == 'Gradient_Descent':\n",
    "                newstepsize = stepsize/nrm\n",
    "                shift_in_paras = newstepsize*(gradient)\n",
    "\n",
    "            elif method == 'AdaGrad':\n",
    "                gradient_sum_square = gradient**2 + gradient_sum_square\n",
    "                shift_in_paras = stepsize*(gradient/np.sqrt(gradient_sum_square))\n",
    "\n",
    "            elif method == 'RMSProp':\n",
    "                gradient_sum_square = (gradient**2)*(1-RMSProp_decay_rate) + gradient_sum_square*RMSProp_decay_rate\n",
    "                shift_in_paras = stepsize*(gradient/np.sqrt(gradient_sum_square))\n",
    "            \n",
    "            new_parameters = shifting_sigm_parameters(parameters, shift_in_paras, delta)\n",
    "            \n",
    "            U = parameter_based_unitary(new_parameters,delta)\n",
    "            Y_new = Y_calculator_wrapper(sep_state_set, rho, U)\n",
    "            Y_new = abs(Y_new[0]).real\n",
    "\n",
    "            Y_correction.append(Y_new)\n",
    "\n",
    "            Y_correction_max = max(Y_correction_max,Y_new)\n",
    "\n",
    "            parameters = new_parameters\n",
    "        \n",
    "    elif method in ['Momentum','Adam']:\n",
    "        for _ in range(max_iterations):\n",
    "            gradient = Gradient(sep_state_set,rho,U,parameters,delta) \n",
    "            gradient = np.array(gradient)\n",
    "\n",
    "            if method == 'Momentum':\n",
    "                gradient_sum = gradient + momentum_decay_rate*gradient_sum\n",
    "                shift_in_paras = stepsize*gradient_sum\n",
    "\n",
    "            elif method == 'Adam':\n",
    "                gradient_sum = gradient*(1-Adam_Beta_momentum) + Adam_Beta_momentum*gradient_sum\n",
    "                gradient_sum_square = (gradient**2)*(1-Adam_Beta_RMS) + gradient_sum_square*(Adam_Beta_RMS)\n",
    "                shift_in_paras = stepsize*(gradient_sum/np.sqrt(gradient_sum_square))\n",
    "\n",
    "            new_parameters = shifting_sigm_parameters(parameters, shift_in_paras, delta)\n",
    "\n",
    "            U = parameter_based_unitary(new_parameters,delta)\n",
    "            Y_new = Y_calculator_wrapper(sep_state_set, rho, U)\n",
    "            Y_new = abs(Y_new[0]).real\n",
    "\n",
    "            Y_correction.append(Y_new)\n",
    "\n",
    "            Y_correction_max = max(Y_correction_max,Y_new)\n",
    "\n",
    "            parameters = new_parameters\n",
    "                \n",
    "    if return_parameters:\n",
    "        return Y_correction,(Y_correction_max,parameters)\n",
    "    else:\n",
    "        return Y_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These are helper function for the final test function. Rn is to calculate the R_n function. PPT_K2_limit and PPT_N2_limit are function to return PPT limits of collectibility for bipartite quNit  and multipartite qubit systems respectively.  \n",
    "'''\n",
    "def Rn(D,Tr,Tr2,N):\n",
    "    E = Tr2/(Tr**2)\n",
    "    D_ = D-N\n",
    "   \n",
    "    inside_sqrt = (D+D_-1)**2 + 4*D*D_*(E-1)\n",
    "\n",
    "    P = (D+D_-1 - math.sqrt(inside_sqrt))/(2*D*D_)\n",
    "    R = (((Tr)/(N))**N)*((1-D*P)**((N-1)/(2)))*((1-D_*P)**((N+1)/(2)))\n",
    "\n",
    "    def PPT_K2_limit(N,K):\n",
    "    return N**(-2*N)\n",
    "\n",
    "def PPT_N2_limit(N,K):\n",
    "    return 1/(16*(2**(K-1)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function is utilizing the bisection method to determin the critical purity for given collectibility limits.\n",
    "'''\n",
    "def bisection(f, a, b,N,K,Y, tolerance=1e-7, max_iterations=100):\n",
    "    \"\"\"\n",
    "    Bisection method for finding the root of a function.\n",
    "    \n",
    "    :param f: Function whose root is to be found\n",
    "    :param a: Lower bound of the interval\n",
    "    :param b: Upper bound of the interval\n",
    "    :param tolerance: Tolerance (default: 1e-7)\n",
    "    :param max_iterations: Maximum number of iterations (default: 100)\n",
    "    :return: The root of the function f\n",
    "    \"\"\"\n",
    "    if f(a,N,K,Y) * f(b,N,K,Y) >= 0:\n",
    "        raise ValueError('f(a) and f(b) must have opposite signs')\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        c = (a + b) / 2\n",
    "        if f(c,N,K,Y) == 0 or (b - a) / 2 < tolerance:\n",
    "            return c\n",
    "        if f(c,N,K,Y) * f(a,N,K,Y) < 0:\n",
    "            b = c\n",
    "        else:\n",
    "            a = c\n",
    "            \n",
    "    raise Exception('Maximum iterations reached. No root found within tolerance.')\n",
    "\n",
    "# Define the function for bisection\n",
    "def Bisection_Rn(x,N,K,Y):\n",
    "    D = N**K\n",
    "    Tr=1\n",
    "    return Rn(D,Tr,x,N) - Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bde183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tests_on_Collectibility(system, rho, IsWerner, delta, method_list, max_iterations=2**10,max_iterations_GD = 100, visual_interval=100,iteration_print_interval=10):\n",
    "    '''\n",
    "    This function uses all the functionality, utilizing Gradient descent using its various methods to determine Collectibility Estimate and gives a visualization of the the performance of the each methods and generates a report with all the results as promised in this thesis work.  \n",
    "    Input: Give me a system to test, the density matrix (rho) of the state and Garadient Descent Varients from ['Gradient_Descent', 'Random', 'RMS Prop', 'AdaGrad', 'Adam', 'momentum' ] to test its collectibility.    \n",
    "    Output: And then it detects NPPT states and characterizes the state in other ways possible using Entanglement collectibility.\n",
    "    '''\n",
    "    rho = np.array(rho)\n",
    "    rho_sqr = np.matmul(rho,rho)\n",
    "    \n",
    "    limits_list = {}\n",
    "    max_parameters = []\n",
    "    Y_max = 0\n",
    "    \n",
    "    K = len(system)\n",
    "    if K<=1:\n",
    "        raise Exception(\"InputError: The system has no subsystems.\")\n",
    "        \n",
    "    if all(list(i == system[0] for i in system)):\n",
    "        N = system[0]\n",
    "    else:\n",
    "        raise Exception(\"InputError: The system has different dimensional subsystems.\")\n",
    "        \n",
    "    D = N**K\n",
    "    Trace = rho.trace().real\n",
    "    if not math.isclose(Trace,1,rel_tol = 1e-4):\n",
    "        raise Exception(f\"InputError: Trace of Density Matrix is not 1. It is {Trace}. Invalid Density Matrix.\")\n",
    "        \n",
    "    Purity = rho_sqr.trace().real\n",
    "    General_Y_limit = Rn(D, Trace, Purity,N)\n",
    "    \n",
    "    limits_list['General_Y_Upper_Bound'] = General_Y_limit\n",
    "    \n",
    "    #Bisection variables: \n",
    "    a = (N**K)**(-1)\n",
    "    b = 1\n",
    "    tolerance = 1e-7\n",
    "    max_bisection_iterations = 100\n",
    "    \n",
    "    if K == 2:\n",
    "        PPT_limit = PPT_K2_limit(N,K)\n",
    "        PPT_critical_Purity = bisection(Bisection_Rn, a, b,N,K,PPT_limit,tolerance,max_bisection_iterations)\n",
    "        if IsWerner:\n",
    "            werner_Collectibility = ymax_werner(N,alpha,amps)\n",
    "            limits_list['Werner_Y'] = werner_Collectibility\n",
    "            Message = f'The system is a werner state (K={K}), with each subsystem being N={N}-dimensional.'\n",
    "            \n",
    "    elif N==2:\n",
    "        PPT_limit = PPT_N2_limit(N,K)\n",
    "        PPT_critical_Purity = bisection(Bisection_Rn, a, b,N,K,PPT_limit,tolerance,max_bisection_iterations)\n",
    "        Message = f'The system is a {K}-partite system, with each subsystem being N={N}-dimensional.'\n",
    "    else:\n",
    "        Message = f'The system is a {K}-partite system, with each subsystem being N={N}-dimensional.'\n",
    "        \n",
    "    limits_list['PPT_limit'] = PPT_limit\n",
    "        \n",
    "    if N==2 or K==2:\n",
    "        if Purity<PPT_critical_Purity:\n",
    "            Message = Message + f'\\nPurity({round(Purity,4)}) is less than Critical Purity ({round(PPT_critical_Purity,4)}).\\nHence, collectibility should not be able to detect NPPT. But we run the algorithm anyway, to be sure.'\n",
    "        else:\n",
    "            Message = Message + f'\\nPurity({round(Purity,4)}) is more than Critical Purity ({round(PPT_critical_Purity,4)}). \\nHence, we calculate collectibility to see if the state is NPPT.'\n",
    "    print(Message)\n",
    "        \n",
    "    #Y_calculation\n",
    "    methods_so_far = []\n",
    "    max_Y = {}\n",
    "    method_time = {}\n",
    "    Collectibility_calculations = {}\n",
    "    \n",
    "    color_scheme = {'Werner_Y':'g','General_Y_Upper_Bound':'r','PPT_limit':'c'}\n",
    "    animate = lambda k: l.set_data(t,max_Y[method])\n",
    "    \n",
    "    for method in method_list:\n",
    "        methods_so_far.append(method)\n",
    "        max_Y[method] = [0]\n",
    "        \n",
    "        method_iteration = 0\n",
    "        method_time[method] = [0]\n",
    "\n",
    "        print('Method - '+ method)\n",
    "                \n",
    "        for i in range(1, max_iterations + 1):\n",
    "            if i%iteration_print_interval==0:\n",
    "                print(i)\n",
    "                \n",
    "            t1 = time.time()\n",
    "            GD,Y_max_parameters = Gradient_Descent(system,rho,delta,max_iterations_GD,True,method)\n",
    "\n",
    "            t2 = time.time()\n",
    "            \n",
    "            method_time[method].append(method_time[method][-1]+t2-t1)\n",
    "            \n",
    "            max_Y[method].append(max(max_Y[method][-1],GD[-2]))\n",
    "            \n",
    "            if max_Y[method][-1] <= Y_max_parameters[0]:\n",
    "                max_parameters = Y_max_parameters[1]\n",
    "                Y_max = Y_max_parameters[0]\n",
    "                \n",
    "            # Visualizing\n",
    "            if i%visual_interval==0:\n",
    "                fig, ax = plt.subplots()\n",
    "                \n",
    "                t = method_time[method]\n",
    "                for m in methods_so_far:\n",
    "                    if max_Y[method][-1]<PPT_limit:\n",
    "                        linclr = 'g'\n",
    "                    else:\n",
    "                        linclr = 'r'\n",
    "                    l, = ax.plot(t,max_Y[m][:len(t)],linestyle = '-.',label=method)\n",
    "    \n",
    "                for key in limits_list:\n",
    "                    plt.axhline(limits_list[key],color = color_scheme[key],label=key)\n",
    "\n",
    "                plt.title(f'Iterations({i}/{max_iterations}) vs Y_collectibility ({method})')\n",
    "                plt.ylabel('Y_collectibility')\n",
    "                plt.xlabel(f'Time(s)')\n",
    "\n",
    "                handles, _ = ax.get_legend_handles_labels()\n",
    "\n",
    "                plt.legend(handles = handles, labels = methods_so_far, loc = 'best')\n",
    "                \n",
    "                if IsWerner:\n",
    "                    method_accuracy = round(max_Y[method][-1]/werner_Collectibility*100, 2)\n",
    "                    plt.annotate('Werner_Y' + f'({method_accuracy}%)', xy = (t[-1],werner_Collectibility)) \n",
    "                    \n",
    "                for lmt in limits_list:\n",
    "                    if lmt!='Werner_Y':\n",
    "                        plt.annotate(lmt, xy = (t[-1],limits_list[lmt]))\n",
    "                \n",
    "                plt.annotate(method, xy = (i,round(max_Y[method][-1],4)))\n",
    "                \n",
    "                animate(len(t))\n",
    "                clear_output(wait=True)\n",
    "                print(Message+'\\n')\n",
    "                print('Method - '+method)\n",
    "                display(fig)\n",
    "                \n",
    "        method_collectibility_max = max_Y[method][-1]\n",
    "        Collectibility_calculations[method] = [method,method_collectibility_max,method_time[method][-1],len(method_time[method])-1]\n",
    "\n",
    "    #Graph display\n",
    "    clear_output(wait=True)\n",
    "    print('\\n'+Message+'\\n')\n",
    "    display(fig)\n",
    "\n",
    "    #Report Display\n",
    "    Final_Collectibility = [0,0,0,0]\n",
    "    for method in methods_so_far:\n",
    "        if Collectibility_calculations[method][1]>Final_Collectibility[1]:\n",
    "            Final_Collectibility = Collectibility_calculations[method]\n",
    "    \n",
    "    Y_estimate_list = list(Collectibility_calculations.values())\n",
    "    print(tabulate(Y_estimate_list, headers=[\"Method\", \"Y Estimates\", \"Time(s)\", \"Iterations\"]))\n",
    "            \n",
    "    print(f'\\nThe \"{Final_Collectibility[0]}\" method produced the\\nMaximum Collectibility Estimate: {round(Final_Collectibility[1],6)}\\nin {round(Final_Collectibility[2],2)} seconds \\nwith {Final_Collectibility[3]} iterations.\\n')\n",
    "    \n",
    "    print (tabulate(list(map(list, limits_list.items())), headers=[\"Limit\", \"Limit Value\"]))\n",
    "    \n",
    "    if K==2 or N==2:\n",
    "        if Final_Collectibility[1]>limits_list['PPT_limit']:\n",
    "            print(f'\\nFinal collectibility estimate is above the PPT threshold,\\nhence NPPT state detected.')\n",
    "        else:\n",
    "            print(f'\\nFinal collectibility estimate is below the PPT threshold,\\nhence cannot be conclusive about the PPT condition for given state.')\n",
    "\n",
    "    # Maximizing N Separable state set: \n",
    "    U_max = parameter_based_unitary(max_parameters,delta)\n",
    "    Local_unitary_list = [U_max[n][0] for n in range(len(U_max))]\n",
    "    Total_U_max = tensor_product(Local_unitary_list)\n",
    "    sep_state_set = Seperable_state_set_generator(Mutually_Orthogonal_state_generator(system))\n",
    "    \n",
    "    max_pure_states = []\n",
    "    for sep_state in sep_state_set:\n",
    "        max_pure_states.append(Total_U_max*sep_state)\n",
    "    \n",
    "    mutuality_test_matrix = []\n",
    "    for i in range(len(max_pure_states)):\n",
    "        mutuality_test_matrix.append([])\n",
    "        for j in range(len(max_pure_states)):\n",
    "            dot_prod = Qobj(max_pure_states[i]).dag()*max_pure_states[j]\n",
    "            if (cmath.isclose(dot_prod,0,abs_tol=1e-9)):\n",
    "                mutuality_test_matrix[i].append(0)\n",
    "            elif (cmath.isclose(dot_prod,1,abs_tol=1e-9)):\n",
    "                mutuality_test_matrix[i].append(1)\n",
    "\n",
    "    # Generating corresponding Observables:\n",
    "    if np.allclose(mutuality_test_matrix,np.eye(N)):\n",
    "        print('\\nThe mutually Orthogonal Seperable state set maximizing the estimated Collectibility Y_max is: ')\n",
    "        pprint(max_pure_states)\n",
    "        \n",
    "        print('\\nThe corresponding observables are: ')\n",
    "        \n",
    "        Observables = []\n",
    "        comb = combinations_with_replacement(list(range(len(max_pure_states))), 2)\n",
    "        for pair in comb:\n",
    "            (i,j) = pair\n",
    "            if i==j:\n",
    "                XiXj = Qobj(max_pure_states[j])*Qobj(max_pure_states[i]).dag()\n",
    "                Observables.append(np.array(XiXj))\n",
    "                print(i,j,XiXj)\n",
    "            else:\n",
    "                XiXj = Qobj(max_pure_states[j])*Qobj(max_pure_states[i]).dag()\n",
    "                Obs = np.array((XiXj+XiXj.dag()).full())\n",
    "                Obs_dag = complex(0,1)*np.array((XiXj-XiXj.dag()).full())\n",
    "                Observables.append(Obs)\n",
    "                Observables.append(Obs_dag)\n",
    "                print(i,j,Obs)\n",
    "                print(i,j,Obs_dag)\n",
    "                \n",
    "    else:\n",
    "        raise Exception(f'\\nThe maximizing Seperable state set is not mutually Orthogonal') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
